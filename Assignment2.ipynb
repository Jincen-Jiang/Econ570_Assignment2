{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import graphviz as gr\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Helper_function import fn_generate_multnorm,fn_randomize_treatment,fn_bias_rmse_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Q1 The First Setting\n",
    "\n",
    "The specification of the true model is following with one observed covariates:\n",
    "\n",
    "$y_i = \\tau*T_i+\\beta'*x_i+e_i$\n",
    "\n",
    "There are no confounders and $x_i$ represents the observed covariates\n",
    "\n",
    "The DAG of this setting is following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n",
       "</g>\n",
       "<!-- X1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">X1</text>\n",
       "</g>\n",
       "<!-- X1&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>X1&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f837bb00520>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"X1\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1 Simulate DGP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Define a function to simulate data\n",
    "def fn_generate_data(tau,N,p,beta0,corr = 0.5,conf = True,conx = True,contx = True,contf = True):\n",
    "    #Inputs\n",
    "    # -tau: treatment effect parameter\n",
    "    # -N: Number of observations (Sample size)\n",
    "    # -P: Number of covariates\n",
    "    # -beta0: the matrix of true parameters of the observed covariates\n",
    "    # -corr: Correlation for multivariate normal\n",
    "    # -conf: Indicating the existence of confounding factors\n",
    "    # -conx: Indicating the existence of covariates factors\n",
    "    # -contx: Indicating whether we control the covariates\n",
    "    # -contf: Indicating whether we control the confoundings\n",
    "\n",
    "\n",
    "    nvar = p+1 # Add 1 confounder\n",
    "\n",
    "    if conf == False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "    else:\n",
    "        conf_mult = 1\n",
    "\n",
    "    if conx == False:\n",
    "        conx_mult = 0 # remove observed covariates from outcome\n",
    "    else:\n",
    "        conx_mult = 1\n",
    "\n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    C = allX[:,0].reshape([N,1]) # confounder\n",
    "    X = allX[:,1:] # observed covariates\n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "\n",
    "    Yab = tau*T+conx_mult*X@beta0+conf_mult*0.6*C+err\n",
    "\n",
    "    if contx == False:\n",
    "        X = np.zeros([N,1])\n",
    "\n",
    "    if contf == False:\n",
    "        C = np.zeros([N,1])\n",
    "\n",
    "    return Yab, T, X, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Assign the values to the true model, with $\\tau$ = 2 , $\\beta_1$ = 5,\n",
    "and the sample size will be 100.\n",
    "\n",
    "$y_i = 2*T_i+5*x_1 +e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "tau = 2\n",
    "N = 100\n",
    "p = 1\n",
    "beta0 = np.array([[5]]).reshape(1,-1)\n",
    "\n",
    "Y, T, X, C = fn_generate_data(tau,N,p,beta0,corr = 0.5,conf = False,conx = True,contx = True,contf = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Store the simulated data\n",
    "data_Q1 = np.hstack([Y,T,X,C])\n",
    "data_Q1 = pd.DataFrame(data_Q1)\n",
    "data_Q1.columns = [\"Y\",\"Treatment\",\"X1\",\"Confounder\"]\n",
    "data_Q1.to_csv(\"data_Q1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2 Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Define a function to estimate the treatment effect of random sample using OLS\n",
    "def fn_estimate_params(Y,T,X,C):\n",
    "    #Inputs\n",
    "    # -Y: Outcome value of Dependent Variable\n",
    "    # -T: Indicating the treatment group 0/1\n",
    "    # -X: Value of observed covariates\n",
    "    # -C: Value of Confounders\n",
    "\n",
    "    covar = np.hstack([T,X,C])\n",
    "    idx = np.argwhere(np.all(covar[..., :] == 0, axis=0))\n",
    "    covars = np.delete(covar, idx, axis=1)\n",
    "\n",
    "    mod = sm.OLS(Y,covars)\n",
    "    res = mod.fit()\n",
    "    tauhat = res.params[0]\n",
    "    se_tauhat = res.HC1_se[0]\n",
    "\n",
    "    return tauhat,se_tauhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Define a function to do the monte carlo simulation\n",
    "def run_mc_simulation(n_rep,tau,N,p,beta0,corr = 0.5,conf = False,conx = False,contx = True,contf = True):\n",
    "    #Inputs\n",
    "    # -n_rep: Number of replication time for monte carlo simulation\n",
    "    # -tau: treatment effect parameter\n",
    "    # -N: Number of observations (Sample size)\n",
    "    # -P: Number of covariates\n",
    "    # -beta0: the matrix of true parameters of the observed covariates\n",
    "    # -corr: Correlation for multivariate normal\n",
    "    # -conf: Indicating the existence of confounding factors\n",
    "    # -conx: Indicating the existence of covariates factors\n",
    "    # -contx: Indicating whether we control the covariates\n",
    "    # -contf: Indicating whether we control the confoundings\n",
    "\n",
    "    estDict = {}\n",
    "    for n in N:\n",
    "        tauhats = []\n",
    "        sehats = []\n",
    "        for rep in tqdm(range(n_rep)):\n",
    "            Y,T,X,C = fn_generate_data(tau,n,p,beta0,corr,conf,conx,contx,contf)\n",
    "            tauhat,sehat = fn_estimate_params(Y,T,X,C)\n",
    "            tauhats = tauhats + [tauhat]\n",
    "            sehats = sehats + [sehat]\n",
    "        estDict[n] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "        }\n",
    "\n",
    "    return estDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Define a function to summarize the results of monte carlo simulation\n",
    "def summarize_mc_simulation(tau,n_rep,N,estDict):\n",
    "    tau0 = tau*np.ones([n_rep,1])\n",
    "    for N, results in estDict.items():\n",
    "        (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                             results['sehat'])\n",
    "\n",
    "        print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Case a:\n",
    "I do not control the covariates, which means the \"contx\" will be FALSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1159.14it/s]\n",
      "100%|██████████| 2000/2000 [00:05<00:00, 398.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=1.1698747274078027, RMSE=1.378183213414323, size=0.537\n",
      "N=1000: bias=1.1707029542979976, RMSE=1.2745009146267867, size=0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "beta0 = np.array([[5]]).reshape(1,-1)\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,beta0,corr = 0.5,conf = False,conx = True,contx = False,contf = False)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case b:\n",
    "I control the covariates, which means the \"contx\" will be TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1130.31it/s]\n",
      " 66%|██████▋   | 1329/2000 [00:03<00:01, 414.45it/s]"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "beta0 = np.array([[5]]).reshape(1,-1)\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,beta0,corr = 0.5,conf = False,conx = True,contx = True,contf = False)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Real life example:\n",
    "Students are randomly assigned to participate into a programme which offers extra tutorial aiming to improve\n",
    "their study performance. In order to study the effect of this programme (Treatment variable) on the study performance\n",
    "(Outcome variable), it controls the parents' education (Observed covariates).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Q2 The Second Setting\n",
    "The specification of the true model is following with one confounder:\n",
    "\n",
    "$y_i = \\tau*T_i+\\beta'*c_i+e_i$\n",
    "\n",
    "There is one confounder and no other observed covariates.\n",
    "We assume that $\\tau$ = 2, $\\beta$ = 0.6, therefore:\n",
    "\n",
    "$y_i = 2*T_i+0.6*c_i+e_i$\n",
    "\n",
    "The DAG of this setting is following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- C -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;T -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>C&#45;&gt;T</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>C&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29\"/>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f837bb000d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"C\", \"T\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"C\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this setting, the major difference from the first setting is that\n",
    "the confounder should be generated in a way that is correlated with the treatment.\n",
    "\n",
    "Therefore, we should modify the function \"fn_generate_data\", and to make Treatment also affected by Confounders.\n",
    "\n",
    "The strategy here is to assume treatment is linearly correlated with Confounder, and we use the idea of\n",
    "logistic regression to calculate the probability of treatment. If it is larger than 0.5, it will be treated.\n",
    "Otherwise, it will be in the control group.\n",
    "\n",
    "$T_i = \\beta_0+\\beta_1*c_i+e_i$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Define a function to separate the samples to treated and non treated based on confounders\n",
    "def fn_confounders_treatment(C,N):\n",
    "    #Inputs\n",
    "    # -C: Confounders\n",
    "    # -N: Number of observations (Sample size)\n",
    "\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    treated = 1 + 2 * C + err\n",
    "    treated_prob = 1/(1+np.exp(-treated))\n",
    "\n",
    "    return np.array([(1 if treated_prob[i] >= 0.5 else 0) for i in range(N)]).reshape([N,1])\n",
    "\n",
    "### Define a function to simulate data\n",
    "def fn_generate_data(tau,N,p,beta0,corr = 0.5,conf = True,conx = True,contx = True,contf = True):\n",
    "    #Inputs\n",
    "    # -tau: treatment effect parameter\n",
    "    # -N: Number of observations (Sample size)\n",
    "    # -P: Number of covariates\n",
    "    # -beta0: the matrix of true parameters of the observed covariates\n",
    "    # -corr: Correlation for multivariate normal\n",
    "    # -conf: Indicating the existence of confounding factors\n",
    "    # -conx: Indicating the existence of covariates factors\n",
    "    # -contx: Indicating whether we control the covariates\n",
    "    # -contf: Indicating whether we control the confoundings\n",
    "\n",
    "\n",
    "    nvar = p+1 # Add 1 confounder\n",
    "\n",
    "    if conf == False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "    else:\n",
    "        conf_mult = 1\n",
    "\n",
    "    if conx == False:\n",
    "        conx_mult = 0 # remove observed covariates from outcome\n",
    "    else:\n",
    "        conx_mult = 1\n",
    "\n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    C = allX[:,0].reshape([N,1]) # confounder\n",
    "    X = allX[:,1:] # observed covariates\n",
    "\n",
    "    T = fn_confounders_treatment(C,N) # choose treated units with the effect of C\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "\n",
    "    Yab = tau*T+conx_mult*X@beta0+conf_mult*0.6*C+err\n",
    "\n",
    "    if contx == False:\n",
    "        X = np.zeros([N,1])\n",
    "\n",
    "    if contf == False:\n",
    "        C = np.zeros([N,1])\n",
    "\n",
    "    return Yab, T, X, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1 Simulate DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "tau = 2\n",
    "N = 100\n",
    "p = 1\n",
    "beta0 = np.array([[5]]).reshape(1,-1)\n",
    "\n",
    "Y, T, X, C = fn_generate_data(tau,N,p,beta0,corr = 0.5,conf = True,conx = False,contx = False,contf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Store the simulated data\n",
    "data_Q2 = np.hstack([Y,T,X,C])\n",
    "data_Q2 = pd.DataFrame(data_Q2)\n",
    "data_Q2.columns = [\"Y\",\"Treatment\",\"X1\",\"Confounder\"]\n",
    "data_Q2.to_csv(\"data_Q2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Monte Carlo Simulation\n",
    "### Case a:\n",
    "I do not control the confounders, which means the \"contf\" will be FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1080.37it/s]\n",
      "100%|██████████| 2000/2000 [00:05<00:00, 397.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.2814458355214624, RMSE=0.33137049295230814, size=0.5465\n",
      "N=1000: bias=0.2804839195593515, RMSE=0.3051698471701159, size=0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(20)\n",
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "beta0 = np.array([[5]]).reshape(1,-1)\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,beta0,corr = 0.5,conf = True,conx = False,contx = False,contf = False)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case b:\n",
    "I control the confounders, which means the \"contf\" will be TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:03<00:00, 630.38it/s]\n",
      "100%|██████████| 2000/2000 [00:06<00:00, 290.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.000289415940535101, RMSE=0.13096272489991012, size=0.0525\n",
      "N=1000: bias=0.0019991305035177314, RMSE=0.042171385297211796, size=0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(20)\n",
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "beta0 = np.array([[5]]).reshape(1,-1)\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,beta0,corr = 0.5,conf = True,conx = False,contx = False,contf = True)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Real life example:\n",
    "If one wants to analyze the effect of smoking (Treatment variable) on the mortality (Outcome Variable),\n",
    "the interpretation of the difference between groups needs to be cautious. Since the gender is likely to be the confounding\n",
    "variables.it is known that males are more likely to smoke than females, and males are also more likely\n",
    "to die young as a result of other general risk-raking behavior. In this case, the higher mortality rate among smokers\n",
    "has nothing to do with (or at least is not entirely due to) the smoking itself, but rather is to do gender discrepancies\n",
    "and the differences in risk-taking behaviors afforded by such a discrepancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Q3 The Third Setting\n",
    "The specification of the true model is following with no confounder and no observed covariates\n",
    "\n",
    "$y_i = \\tau*T_i+e_i$\n",
    "\n",
    "but there is a mediators between the path from the treatment to the outcome, which is affected by the treatment:\n",
    "\n",
    "$X_i = \\beta_0+\\beta_1*T_i+e_i$\n",
    "\n",
    "Then, the true model can be written as:\n",
    "\n",
    "$y_i = \\tau'*T_i+ \\lambda*X_i + e_i$\n",
    "\n",
    "where $\\tau = \\tau' + \\lambda * \\beta_1$\n",
    "\n",
    "The DAG of this setting is following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"red\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f8d93f35f40>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"X\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.node(\"X\", \"X\", color=\"red\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's assume $\\tau =2, \\tau' = 1.5, \\lambda = 0.25, \\beta_1 = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Define a function to simulate data\n",
    "def fn_generate_selection_data(tau1,N,beta1,lambda_x,conts = False):\n",
    "    #Inputs\n",
    "    # -tau: treatment effect parameter\n",
    "    # -N: Number of observations (Sample size)\n",
    "    # -conts: Indicating whether we control the mediators(selection bias variable)\n",
    "\n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err1 = np.random.normal(0,10,[N,1])\n",
    "    X = 0.5 + beta1*T + err1\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "\n",
    "    Yab = tau1*T+lambda_x*X+err\n",
    "\n",
    "    if conts == False:\n",
    "        X = np.zeros([N,1])\n",
    "\n",
    "    return Yab, T, X\n",
    "\n",
    "### Define a function to estimate the treatment effect of random sample using OLS\n",
    "def fn_estimate_params(Y,T,X):\n",
    "    #Inputs\n",
    "    # -Y: Outcome value of Dependent Variable\n",
    "    # -T: Indicating the treatment group 0/1\n",
    "    # -X: Value of Mediators(selection bias variable)\n",
    "\n",
    "    covar = np.hstack([T,X])\n",
    "    idx = np.argwhere(np.all(covar[..., :] == 0, axis=0))\n",
    "    covars = np.delete(covar, idx, axis=1)\n",
    "\n",
    "    mod = sm.OLS(Y,covars)\n",
    "    res = mod.fit()\n",
    "    tauhat = res.params[0]\n",
    "    se_tauhat = res.HC1_se[0]\n",
    "\n",
    "    return tauhat,se_tauhat\n",
    "\n",
    "### Define a function to do the monte carlo simulation\n",
    "def run_mc_simulation(n_rep,tau1,N,beta1,lambda_x,conts = False):\n",
    "    #Inputs\n",
    "    # -n_rep: Number of replication time for monte carlo simulation\n",
    "    # -tau: treatment effect parameter\n",
    "    # -N: Number of observations (Sample size)\n",
    "    # -conts: Indicating whether we control the mediators(selection bias variable)\n",
    "\n",
    "    estDict = {}\n",
    "    for n in N:\n",
    "        tauhats = []\n",
    "        sehats = []\n",
    "        for rep in tqdm(range(n_rep)):\n",
    "            Y,T,X = fn_generate_selection_data(tau1,n,beta1,lambda_x,conts)\n",
    "            tauhat,sehat = fn_estimate_params(Y,T,X)\n",
    "            tauhats = tauhats + [tauhat]\n",
    "            sehats = sehats + [sehat]\n",
    "        estDict[n] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "        }\n",
    "\n",
    "    return estDict\n",
    "\n",
    "### Define a function to summarize the results of monte carlo simulation\n",
    "def summarize_mc_simulation(tau1,lambda_x,beta1,n_rep,N,estDict):\n",
    "    tau0 = (tau1+lambda_x*beta1)*np.ones([n_rep,1])\n",
    "    for N, results in estDict.items():\n",
    "        (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                             results['sehat'])\n",
    "\n",
    "        print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Simulate DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "tau1 = 1.5\n",
    "lambda_x = 0.25\n",
    "beta1 = 2\n",
    "N = 100\n",
    "\n",
    "#True tau\n",
    "tau = tau1 + lambda_x*beta1\n",
    "\n",
    "Y, T, X = fn_generate_selection_data(tau1,N,beta1,lambda_x,conts = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Store the simulated data\n",
    "data_Q3 = np.hstack([Y,T,X])\n",
    "data_Q3 = pd.DataFrame(data_Q3)\n",
    "data_Q3.columns = [\"Y\",\"Treatment\",\"Mediators\"]\n",
    "data_Q3.to_csv(\"data_Q3.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Monte Carlo Simulation\n",
    "### Case a:\n",
    "I control the mediators(selection bias variable), which means the \"conts\" will be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1477.95it/s]\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 134.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.5016565887292146, RMSE=0.523037044433964, size=0.928\n",
      "N=1000: bias=-0.50138818674844, RMSE=0.5035352156825205, size=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "np.random.seed(100)\n",
    "tau1 = 1.5\n",
    "lambda_x = 0.25\n",
    "beta1 = 2\n",
    "N = [100,1000]\n",
    "\n",
    "#True tau\n",
    "tau = tau1 + lambda_x*beta1\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau1,N,beta1,lambda_x,conts=True)\n",
    "summarize_mc_simulation(tau1,lambda_x,beta1,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case b:\n",
    "I do not control the mediators(selection bias variable), which means the \"conts\" will be False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1492.09it/s]\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 144.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.13722903094455685, RMSE=0.411879232912311, size=0.0795\n",
      "N=1000: bias=0.12385841614261445, RMSE=0.1740604085395366, size=0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "np.random.seed(100)\n",
    "tau1 = 1.5\n",
    "lambda_x = 0.25\n",
    "beta1 = 2\n",
    "N = [100,1000]\n",
    "\n",
    "#True tau\n",
    "tau = tau1 + lambda_x*beta1\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau1,N,beta1,lambda_x,conts=False)\n",
    "summarize_mc_simulation(tau1,lambda_x,beta1,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Real life example\n",
    "In the study of the effect of education (Treatment variable) on the income level (Outcome variable), there is likely to be\n",
    "a mediator such as white collar job (selection bias variable), which exists between the path from the treatment to the outcome.\n",
    "More educated people are more likely to have higher wage, and also more likely to be a white collar, and then the white collar\n",
    "will lead to a higher wage. Thus, if conditioning on the white collar variable, we would biase the causal effect estimation since\n",
    "it closes one of the channels through which the treatment operates, and it will induce a negative bias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}